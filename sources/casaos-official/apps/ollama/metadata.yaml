architecture: all
debian_section: comm
description: Get up and running with large language models locally
homepage: null
icon: https://cdn.jsdelivr.net/gh/IceWhaleTech/CasaOS-AppStore@main/Apps/Ollama/icon.png
license: Unknown
long_description: 'Ollama is a tool for running large language models locally, designed
  to help users quickly deploy and manage AI models via a simple command-line interface
  and server. Its intuitive Web interface and efficient design make it ideal for developers,
  researchers, and AI enthusiasts working on local hardware.


  The tool''s core features include local model execution and multi-model support.
  It enables running models like Llama 3, Mistral, and Gemma, with simple commands
  for downloading and switching models. All data processing occurs locally, ensuring
  privacy. Low resource usage optimizes model loading, allowing smooth operation on
  limited hardware.


  It offers a RESTful API for application integration and supports tool calling (e.g.,
  Llama 3.1) for complex tasks. Model management via Modelfile bundles weights and
  configurations for ease of use. The tool''s efficiency and user control deliver
  a modern local AI solution.


  **Key Features:**

  - **Local Execution**: Run LLMs directly on your hardware without internet dependency

  - **Multiple Model Support**: Access to dozens of pre-trained models including Llama
  3, Mistral, Gemma, Code Llama, and more

  - **Easy Model Management**: Simple commands to pull, run, and manage different
  models

  - **API Integration**: RESTful API for building applications and integrations

  - **Memory Efficient**: Optimized model loading and memory management

  - **Privacy-Focused**: All processing happens locally, ensuring data privacy


  **Supported Models:**

  - DeepSeek-R1 (1.5B, 7B, 8B, 14B, 32B, 70B, 671B parameters)

  - Gemma3n (2B, 4B parameters)

  - Gemma3 (1B, 4B, 12B, 27B parameters)

  - Qwen3 (0.6B, 1.7B, 4B, 8B, 14B, 30B, 32B, 235B parameters)

  - Qwen2.5vl (3B, 7B, 32B, 72B parameters)

  - Llama3.1 (8B, 70B, 405B parameters)

  - Llama3.2 (1B, 3B parameters)

  - Mistral (7B parameters)

  - And many more...


  **Use Cases:**

  - Local AI development and experimentation

  - Educational purposes and research

  - Building AI-powered applications

  - Code generation and assistance

  - Text generation and completion

  - Chatbots and conversational AI

  - Data analysis and insights


  **Learn More:**

  - [Ollama Official Website](https://ollama.com/)

  - [Ollama GitHub Repository](https://github.com/ollama/ollama)

  - [Model Library](https://ollama.com/library)

  '
maintainer: ollama <auto-converted@casaos.io>
name: ollama
package_name: casaos-ollama-container
screenshots:
- https://cdn.jsdelivr.net/gh/IceWhaleTech/CasaOS-AppStore@main/Apps/Ollama/screenshot-1.png
- https://cdn.jsdelivr.net/gh/IceWhaleTech/CasaOS-AppStore@main/Apps/Ollama/screenshot-2.png
- https://cdn.jsdelivr.net/gh/IceWhaleTech/CasaOS-AppStore@main/Apps/Ollama/screenshot-3.png
source_metadata: null
tags:
- role::container-app
version: 1.0.0
